<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.36.1" />
  <meta name="author" content="宋适宇">

  
  
  
  
    
      
    
  
  <meta name="description" content="Summary Scale drift is a crucial challenge for monocular autonomous driving to emulate the performance of stereo. This paper presents a real-time monocular SFM system that corrects for scale drift using a novel cue combination framework for ground plane estimation, yielding accuracy comparable to stereo over long driving sequences. Our ground plane estimation uses multiple cues like sparse features, dense inter-frame stereo and (when applicable) object detection. A data-driven mechanism is proposed to learn models from training data that relate observation covariances for each cue to error behavior of its underlying variables.">

  
  <link rel="alternate" hreflang="en-us" href="https://songshiyu01.github.io/project/monocular_vo/">

  


  

  
  
  <meta name="theme-color" content="#3f51b5">
  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-41234944-2', 'auto');
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  
  <link rel="alternate" href="https://songshiyu01.github.io/index.xml" type="application/rss+xml" title="Shiyu Song">
  <link rel="feed" href="https://songshiyu01.github.io/index.xml" type="application/rss+xml" title="Shiyu Song">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://songshiyu01.github.io/project/monocular_vo/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Shiyu Song">
  <meta property="og:url" content="https://songshiyu01.github.io/project/monocular_vo/">
  <meta property="og:title" content="Monocular Visual Odometry | Shiyu Song">
  <meta property="og:description" content="Summary Scale drift is a crucial challenge for monocular autonomous driving to emulate the performance of stereo. This paper presents a real-time monocular SFM system that corrects for scale drift using a novel cue combination framework for ground plane estimation, yielding accuracy comparable to stereo over long driving sequences. Our ground plane estimation uses multiple cues like sparse features, dense inter-frame stereo and (when applicable) object detection. A data-driven mechanism is proposed to learn models from training data that relate observation covariances for each cue to error behavior of its underlying variables.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2012-02-18T00:00:00-08:00">
  
  <meta property="article:modified_time" content="2012-02-18T00:00:00-08:00">
  

  

  <title>Monocular Visual Odometry | Shiyu Song</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Shiyu Song</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article article-project" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">

    <div class="pub-title">
      <h1 itemprop="name">Monocular Visual Odometry</h1>
      <span class="pub-authors" itemprop="author">&nbsp;</span>
      <span class="pull-right">
        
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Monocular%20Visual%20Odometry&amp;url=https%3a%2f%2fsongshiyu01.github.io%2fproject%2fmonocular_vo%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fsongshiyu01.github.io%2fproject%2fmonocular_vo%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsongshiyu01.github.io%2fproject%2fmonocular_vo%2f&amp;title=Monocular%20Visual%20Odometry"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fsongshiyu01.github.io%2fproject%2fmonocular_vo%2f&amp;title=Monocular%20Visual%20Odometry"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Monocular%20Visual%20Odometry&amp;body=https%3a%2f%2fsongshiyu01.github.io%2fproject%2fmonocular_vo%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


      </span>
    </div>

    

    <div class="article-style" itemprop="articleBody">
      

<h3 id="summary">Summary</h3>

<p>Scale drift is a crucial challenge for monocular autonomous driving to emulate the performance of stereo. This paper presents a real-time monocular SFM system that corrects for scale drift using a novel cue combination framework for ground plane estimation, yielding accuracy comparable to stereo over long driving sequences. Our ground plane estimation uses multiple cues like sparse features, dense inter-frame stereo and (when applicable) object detection. A data-driven mechanism is proposed to learn models from training data that relate observation covariances for each cue to error behavior of its underlying variables. During testing, this allows per-frame adaptation of observation covariances based on relative confidences inferred from visual data. Our framework significantly boosts not only the accuracy of monocular self-localization, but also that of applications like object localization that rely on the ground plane. Experiments on the KITTI dataset demonstrate the accuracy of our ground plane estimation, monocular SFM and object localization relative to ground truth, with detailed comparisons to prior art.</p>

<h3 id="accuracy">Accuracy</h3>

<p>We demonstrate our performance on the KITTI dataset. For camera self-localization, our purely vision-based system achieves a rotation error of 0.005 degrees per meter and a translation error of 2.5%, which compares favorably even to state-of-the-art stereo systems and significantly outperforms other monocular systems. For 3D localization of other traffic participants like cars, we achieve low errors of 8% for near objects (within 30 meters) and 12% for far objects (beyond 30 meters).</p>

<p><img src="/img/monocular_vo_overview.png" alt="The overview of the monocular visual odometry system" /></p>

<h3 id="cue-combination">Cue combination</h3>

<p>The main challenge in monocular SFM is scale drift, since unlike the case of stereo, there is no reference baseline. We overcome this challenge with a novel cue combination framework, that combines information from 3D points, inter-frame stereo and object detection.</p>

<p><img src="/img/monocular_vo_cue.png" alt="The cue combination of the monocular visual odometry system" /></p>

<h3 id="comparison-to-other-systems">Comparison to other systems</h3>

<p>Our real-time monocular SFM is comparable in accuracy to state-of-the-art stereo systems and significantly outperforms other monocular systems. A few example sequences are shown here from the KITTI benchmark.</p>

<p><img src="/img/monocular_vo_comparison.png" alt="The comparison to other systems" /></p>

<h3 id="videos">Videos</h3>

<p>These videos provide a 1-minute description of the paper and demonstrate the monocular visual odometry and 3D object localization results.</p>

<h5 id="overview">Overview</h5>


<div style="position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/RN-WHId0tek" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" allowfullscreen frameborder="0" title="YouTube Video"></iframe>
 </div>


<h5 id="3d-object-localization">3D object localization</h5>


<div style="position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/_uxX_DlJ0CI" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" allowfullscreen frameborder="0" title="YouTube Video"></iframe>
 </div>


<h5 id="monocular-visual-odometry">Monocular visual odometry</h5>


<div style="position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/7orRPfRbhUs" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" allowfullscreen frameborder="0" title="YouTube Video"></iframe>
 </div>


    </div>

    





    
    
    

    
      
      
      
      
        <h2>Publications</h2>
        
          
            <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="author">
    <strong>Shiyu Song</strong>, Manmohan Chandraker, Clark C. Guest</span>.
  <a href="https://songshiyu01.github.io/publication/pami2016_monovo/" itemprop="name">High Accuracy Monocular SFM and Scale Correction for Autonomous Driving</a>.
  <strong>T-PAMI</strong>,
  2016.
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="http://ieeexplore.ieee.org/document/7206590/" target="_blank" rel="noopener">
  Preprint
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://songshiyu01.github.io/pdf/pami2016_monovo.pdf" target="_blank" rel="noopener">
  PDF
</a>








<a class="btn btn-primary btn-outline btn-xs" href="/project/monocular_vo/">
  Project
</a>







</p>
</div>

          
        
          
            <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="author">
    <strong>Shiyu Song</strong>, Manmohan Chandraker</span>.
  <a href="https://songshiyu01.github.io/publication/cvpr2015_object/" itemprop="name">Joint SFM and Detection Cues for Monocular 3D Localization in Road Scenes</a>.
  <strong>CVPR (Oral)</strong>,
  2015.
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="http://ieeexplore.ieee.org/document/7298997/" target="_blank" rel="noopener">
  Preprint
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_043.pdf" target="_blank" rel="noopener">
  PDF
</a>








<a class="btn btn-primary btn-outline btn-xs" href="/project/monocular_vo/">
  Project
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://songshiyu01.github.io/pdf/cvpr2015_object_poster.pdf" target="_blank" rel="noopener">
  Poster
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://www.youtube.com/watch?v=_uxX_DlJ0CI" target="_blank" rel="noopener">
  Video
</a>



</p>
</div>

          
        
          
            <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="author">
    <strong>Shiyu Song</strong>, Manmohan Chandraker</span>.
  <a href="https://songshiyu01.github.io/publication/cvpr2014_monovo/" itemprop="name">Robust Scale Estimation in Real-Time Monocular SFM for Autonomous Driving</a>.
  <strong>CVPR</strong>,
  2014.
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="http://ieeexplore.ieee.org/xpl/abstractMetrics.jsp?tp=&amp;arnumber=6909599" target="_blank" rel="noopener">
  Preprint
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://songshiyu01.github.io/pdf/cvpr2014_monovo.pdf" target="_blank" rel="noopener">
  PDF
</a>








<a class="btn btn-primary btn-outline btn-xs" href="/project/monocular_vo/">
  Project
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://songshiyu01.github.io/pdf/cvpr2014_monovo_poster.pdf" target="_blank" rel="noopener">
  Poster
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://www.youtube.com/watch?v=EK7u9UNdcOU" target="_blank" rel="noopener">
  Video
</a>



</p>
</div>

          
        
          
            <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="author">
    <strong>Shiyu Song</strong>, Manmohan Chandraker, Clark C. Guest</span>.
  <a href="https://songshiyu01.github.io/publication/icra2013_monovo/" itemprop="name">Parallel, Real-Time Monocular Visual Odometry</a>.
  <strong>ICRA</strong>,
  2013.
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="http://ieeexplore.ieee.org/document/6631246/?tp=&amp;arnumber=6631246" target="_blank" rel="noopener">
  Preprint
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://songshiyu01.github.io/pdf/icra2013_monovo.pdf" target="_blank" rel="noopener">
  PDF
</a>








<a class="btn btn-primary btn-outline btn-xs" href="/project/monocular_vo/">
  Project
</a>







</p>
</div>

          
        
      

      
      
      
      
        <h2>Talks</h2>
        
          <div class="pub-list-item" style="margin-bottom: 1rem" itemscope itemtype="http://schema.org/Event">
  <i class="fa fa-comment-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name"><a href="https://songshiyu01.github.io/talk/cvpr2015_monovo/">Joint SFM and Detection Cues for Monocular 3D Localization in Road Scenes</a></span>
  <div itemprop="startDate">
    
    Jun 9, 2015
    
      12:00 AM
    
  </div>
  <div class="talk-metadata">
    
            Oral Presentation in CVPR 2015
    
  </div>
  <div class="talk-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_043.pdf">
  PDF
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://localhost:1313/pdf/cvpr2015_object_poster.pdf">
  Slides
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://www.youtube.com/watch?v=_uxX_DlJ0CI">
  Video
</a>



<a class="btn btn-primary btn-outline btn-xs" href="/project/monocular_vo/">
  Project
</a>



  </div>
</div>

        
      
    

  </div>
</article>



<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 <a href="https://songshiyu01.github.io/" target="_blank">Shiyu Song</a> &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  </body>
</html>

